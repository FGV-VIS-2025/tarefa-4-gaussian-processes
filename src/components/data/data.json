{
    "steps": [
        {
            "type": "step",
            "value": [
                {
                    "type": "p",
                    "value": [
                        {
                            "type": "text",
                            "value": "Suppose you have \\(n\\) points on the plane."
                        }
                    ]
                }
            ],
            "figure": "happy.png"
        },
        {
            "type": "step",
            "value": [
                {
                    "type": "p",
                    "value": [
                        {
                            "type": "text",
                            "value": "If \\(n\\) is small enough, you can imagine it as a sample of a random variable \\(X \\sim F(\\theta)\\) living in \\(\\mathbb{R}^d\\), with \\(d\\) at least as big as \\(n\\)."
                        }
                    ]
                }
            ],
            "figure": "happy.png"
        },
        {
            "type": "step",
            "value": [
                {
                    "type": "p",
                    "value": [
                        {
                            "type": "text",
                            "value": "But as \\(n \\to \\infty\\), things start to get messy. The density \\(F\\) becomes a distribution defined in a very high dimensional space, which involves arithmetic operations of <em>humongous</em> matrices. Depending on how high you shoot, not even the best computers in the world can handle that."
                        }
                    ]
                },
                {
                    "type": "p",
                    "value": [
                        {
                            "type": "text",
                            "value": "So... is there a way we can fix this?"
                        }
                    ]
                }
            ],
            "figure": "thinking.png"
        },
        {
            "type": "step",
            "value": [
                {
                    "type": "p",
                    "value": [
                        {
                            "type": "text",
                            "value": "In the initial setting, we had a bunch of points on the plane, and we assigned to them a distribution which essentially describes the probability of observing certain \\(y\\)'s for fixed regions of the \\(x\\) axis. In other words, for each fixed region of the \\(x\\) axis we assigned a probability, a number."
                        }
                    ]
                },
                {
                    "type": "p",
                    "value": [
                        {
                            "type": "text",
                            "value": "So what if, instead of assigning numbers to specific regions of the \\(x\\) axis, we assign numbers to the whole \\(x\\) line?"
                        }
                    ]
                },
                {
                    "type": "p",
                    "value": [
                        {
                            "type": "text",
                            "value": "Yeah, we're creating a function!"
                        }
                    ]
                }
            ],
            "figure": "super_happy.png"
        },
        {
            "type": "step",
            "value": [
                {
                    "type": "p",
                    "value": [
                        {
                            "type": "text",
                            "value": "A gaussian process is precisely the extension of a gaussian distribution to \\(\\mathbb{R}^{\\infty}\\) following that logic."
                        }
                    ]
                },
                {
                    "type": "p",
                    "value": [
                        {
                            "type": "text",
                            "value": "Why gaussians, specifically? Well, for many reasons, but one of them is that they are <b>marginalizable</b>, which means that if we marginalize a gaussian distribution over a subset of its variables, we get another gaussian distribution. That ties the knot between the stochastic process we defined by this infinite-dimensional function and finite dimensional gaussian distributions."
                        }
                    ]
                },
                {
                    "type": "p",
                    "value": [
                        {
                            "type": "text",
                            "value": "And that sets our definition: a gaussian process is a stochastic process such that any finite collection \\(X_1, \\dots, X_n\\) of values follows a gaussian distribution with mean \\(\\mu(x)\\) and covariance matrix \\(K(X_1, \\dots, X_n)\\)."
                        }
                    ]
                }
            ],
            "figure": "happy.png"
        },
        {
            "type": "step",
            "value": [
                {
                    "type": "p",
                    "value": [
                        {
                            "type": "text",
                            "value": "We can show that \\(\\mu\\) isn't very important compared to \\(K\\), so we'll just set it to zero. "
                        }
                    ]
                },
                {
                    "type": "p",
                    "value": [
                        {
                            "type": "text",
                            "value": "\\(K\\) is called a <b>kernel function</b>, and different kernels lead to very different gaussian processes for the same set of samples."
                        }
                    ]
                }
            ],
            "figure": "happy.png"
        },
        {
            "type": "step",
            "value": [
                {
                    "type": "p",
                    "value": [
                        {
                            "type": "text",
                            "value": "And what's more: as gaussians are closed under conditioning, that means we can mantain our framework in the light of new data, by just updating the mean and covariance matrix of our gaussian process."
                        }
                    ]
                }
            ],
            "figure": "laughing.png"
        }
    ]
}